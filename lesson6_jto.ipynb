{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.3333)\n",
    "#sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]='PCI_BUS_ID'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='2'\n",
    "\n",
    "import keras\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Dense, Lambda, Flatten, Dropout\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.optimizers import Adam, sgd\n",
    "from keras.layers import Input, Embedding, Reshape, merge, LSTM, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.preprocessing import image, sequence\n",
    "from keras.layers import SimpleRNN\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#if 'session' in locals() and session is not None:\n",
    "#    print('Close interactive session')\n",
    "#    session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "1. download collected works of Nietzsche\n",
    "2. get character map\n",
    "3. create idx <-> char map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600901\n"
     ]
    }
   ],
   "source": [
    "path = get_file('nietzsche.txt', origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "text = open(path).read()\n",
    "print(\"corpus length:\", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 86\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)+1\n",
    "print(\"total chars:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n !\"\\'(),-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars.insert(0, \"\\0\") # Sometimes it's useful to have a zero value in the dataset, e.g. for padding\n",
    "''.join(chars[1:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 42, 29, 30, 25, 27, 29, 1, 1, 1]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "idx = [char_indices[c] for c in text]\n",
    "idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREFACE\\n\\n\\nSUPPOSING that Truth is a woman--what then? Is there not gro'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in idx[:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 character model\n",
    "1. Create four lists of every 4th character (starting at 0th, 1st, 2nd, 3rd), 4th list becomes the output, first 3 are inputs\n",
    "2. Define number of latent factors\n",
    "3. Create inputs and embedding outputs for each of the 3 character inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs=3\n",
    "c1_dat = [idx[i] for i in range(0, len(idx)-1-cs, cs)]\n",
    "c2_dat = [idx[i+1] for i in range(0, len(idx)-1-cs, cs)]\n",
    "c3_dat = [idx[i+2] for i in range(0, len(idx)-1-cs, cs)]\n",
    "c4_dat = [idx[i+3] for i in range(0, len(idx)-1-cs, cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#inputs\n",
    "x1 = np.stack(c1_dat[:-2])\n",
    "x2 = np.stack(c2_dat[:-2])\n",
    "x3 = np.stack(c3_dat[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output\n",
    "y = np.stack(c4_dat[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200297,), (200297,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding_input(name, n_in, n_out):\n",
    "    inp = Input(shape=(1,), dtype=\"int64\", name=name)\n",
    "    emb = Embedding(n_in, n_out, input_length=1)(inp)\n",
    "    return inp, Flatten()(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1_in, c1 = embedding_input(\"c1\", vocab_size, n_fac)\n",
    "c2_in, c2 = embedding_input(\"c2\", vocab_size, n_fac)\n",
    "c3_in, c3 = embedding_input(\"c3\", vocab_size, n_fac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train model\n",
    "1. Feed inputs into successive hidden inputs to create model\n",
    "2. Create model from inputs and output, then compile and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 256 #the size of our hidden state\n",
    "dense_in = Dense(n_hidden, activation=\"relu\")\n",
    "dense_hidden = Dense(n_hidden, activation=\"tanh\") #not sure why using tanh activation\n",
    "dense_out = Dense(vocab_size, activation=\"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1_hidden = dense_in(c1)\n",
    "hidden_2 = dense_hidden(c1_hidden) #why do we need 2 dense layers for first character?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c2_dense = dense_in(c2)\n",
    "c2_hidden = merge([c2_dense, hidden_2]) #ah, it's not it's own dense layer as it merges with the dense layer following c2's DL\n",
    "hidden_3 = dense_hidden(c2_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c3_dense = dense_in(c3)\n",
    "c3_hidden = merge([c3_dense, hidden_3])\n",
    "c4_out = dense_out(c3_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model([c1_in, c2_in, c3_in], c4_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())\n",
    "model.optimizer.lr = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "200297/200297 [==============================] - 20s - loss: 4.4173    \n",
      "Epoch 2/4\n",
      "200297/200297 [==============================] - 17s - loss: 4.2973    \n",
      "Epoch 3/4\n",
      "200297/200297 [==============================] - 17s - loss: 4.0440    \n",
      "Epoch 4/4\n",
      "200297/200297 [==============================] - 17s - loss: 3.6600    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1624abb41d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x1, x2, x3], y, batch_size=64, nb_epoch=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "200297/200297 [==============================] - 17s - loss: 3.3425    \n",
      "Epoch 2/4\n",
      "200297/200297 [==============================] - 17s - loss: 3.2007    \n",
      "Epoch 3/4\n",
      "200297/200297 [==============================] - 17s - loss: 3.1453    \n",
      "Epoch 4/4\n",
      "200297/200297 [==============================] - 17s - loss: 3.1208    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1624e9287f0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr=0.01\n",
    "model.fit([x1, x2, x3], y, batch_size=64, nb_epoch=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "200297/200297 [==============================] - 17s - loss: 3.1057    \n",
      "Epoch 2/4\n",
      "200297/200297 [==============================] - 17s - loss: 3.0944    \n",
      "Epoch 3/4\n",
      "200297/200297 [==============================] - 17s - loss: 3.0852    \n",
      "Epoch 4/4\n",
      "200297/200297 [==============================] - 17s - loss: 3.0772    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1624bdf4e48>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr=0.000001\n",
    "model.fit([x1, x2, x3], y, batch_size=64, nb_epoch=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "200297/200297 [==============================] - 17s - loss: 2.9363    \n",
      "Epoch 2/8\n",
      "200297/200297 [==============================] - 17s - loss: 2.9272    \n",
      "Epoch 3/8\n",
      "200297/200297 [==============================] - 17s - loss: 2.9182    \n",
      "Epoch 4/8\n",
      "200297/200297 [==============================] - 17s - loss: 2.9094    \n",
      "Epoch 5/8\n",
      "200297/200297 [==============================] - 17s - loss: 2.9007    \n",
      "Epoch 6/8\n",
      "200297/200297 [==============================] - 17s - loss: 2.8920    \n",
      "Epoch 7/8\n",
      "200297/200297 [==============================] - 17s - loss: 2.8835    \n",
      "Epoch 8/8\n",
      "200297/200297 [==============================] - 17s - loss: 2.8751    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1624be0c048>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr=0.1\n",
    "model.fit([x1, x2, x3], y, batch_size=64, nb_epoch=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = [np.array(i)[np.newaxis] for i in idxs]\n",
    "    p = model.predict(arrs)\n",
    "    #p[0,2] = 0.\n",
    "    i = np.argmax(p)\n",
    "    print(p, i)\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.54865657e-08   1.49483392e-02   2.31783956e-01   3.42995889e-04\n",
      "    2.17914209e-03   2.19642388e-04   2.41972826e-04   2.25413038e-04\n",
      "    1.16145182e-02   4.25912021e-03   3.10039613e-03   4.65834455e-05\n",
      "    1.75333931e-04   1.07757573e-04   6.08266528e-05   7.72587300e-05\n",
      "    6.23737724e-05   4.75745765e-05   7.50205363e-05   5.84467343e-05\n",
      "    4.39511459e-05   6.12729753e-04   5.35177591e-04   2.77365005e-04\n",
      "    3.13706842e-04   8.68282572e-04   1.58230527e-04   2.96991813e-04\n",
      "    2.44640629e-04   8.93161923e-04   2.26080971e-04   3.19226732e-04\n",
      "    3.58226011e-04   9.42568993e-04   5.34119536e-05   6.89832304e-05\n",
      "    2.47740099e-04   3.08572256e-04   4.37793642e-04   6.21995248e-04\n",
      "    3.19327664e-04   3.35107143e-05   4.38114774e-04   6.61385653e-04\n",
      "    1.13678875e-03   2.42030277e-04   8.68161223e-05   2.82969064e-04\n",
      "    2.38959619e-05   8.88590657e-05   1.48742311e-05   6.05629393e-05\n",
      "    8.13349106e-05   1.00482539e-04   4.28723432e-02   6.57961145e-03\n",
      "    1.71233453e-02   2.69237328e-02   1.49793863e-01   1.22806318e-02\n",
      "    1.29057765e-02   4.55684215e-02   6.52875900e-02   4.12125752e-04\n",
      "    2.05168501e-03   3.21088620e-02   1.71102453e-02   3.87557037e-02\n",
      "    4.53737453e-02   1.21544069e-02   5.02757379e-04   3.64337862e-02\n",
      "    5.43468297e-02   5.23047410e-02   1.85517631e-02   6.12439727e-03\n",
      "    9.69217438e-03   7.57410773e-04   1.27355112e-02   1.95303975e-04\n",
      "    6.54338601e-06   4.98676407e-08   5.84297049e-06   4.56437874e-08\n",
      "    1.41916707e-05   2.92654487e-08]] 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(\" it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.34416619e-08   1.48813818e-02   1.38626382e-01   3.34294862e-04\n",
      "    2.02722312e-03   2.25922078e-04   2.95426260e-04   2.30270147e-04\n",
      "    1.01653319e-02   4.37463820e-03   3.50177567e-03   4.24712453e-05\n",
      "    1.56955153e-04   1.04906991e-04   7.10012537e-05   7.22971745e-05\n",
      "    6.11220967e-05   4.40359290e-05   9.89522377e-05   6.64726831e-05\n",
      "    4.57423739e-05   6.02927874e-04   5.51924924e-04   2.98252155e-04\n",
      "    3.28984577e-04   7.08951324e-04   1.63710487e-04   3.19173239e-04\n",
      "    2.56780593e-04   1.01145206e-03   2.79002881e-04   3.65013635e-04\n",
      "    3.39378603e-04   1.00887695e-03   5.70278316e-05   6.66475025e-05\n",
      "    2.38061897e-04   2.52433878e-04   5.14382380e-04   6.42251864e-04\n",
      "    3.34446988e-04   3.53291070e-05   4.36303089e-04   6.84067432e-04\n",
      "    9.31250397e-04   2.51056772e-04   9.88259562e-05   2.74188991e-04\n",
      "    2.47217158e-05   9.68689419e-05   1.71358461e-05   5.94933445e-05\n",
      "    9.07268113e-05   1.09722088e-04   6.45893738e-02   7.24847987e-03\n",
      "    1.58706084e-02   2.94733010e-02   2.56496578e-01   1.29471524e-02\n",
      "    8.56381096e-03   2.04768162e-02   6.44352138e-02   4.19853139e-04\n",
      "    2.05983664e-03   2.98818871e-02   1.67628955e-02   3.62161063e-02\n",
      "    4.58655283e-02   1.09374775e-02   5.68421616e-04   4.18670662e-02\n",
      "    4.89299223e-02   5.33456057e-02   1.73102170e-02   6.30795583e-03\n",
      "    1.04936017e-02   7.09846034e-04   1.11145973e-02   2.03136660e-04\n",
      "    7.29437716e-06   5.78820618e-08   6.63566789e-06   5.90551075e-08\n",
      "    1.45271870e-05   3.73226072e-08]] 58\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(\" th\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our first RNN\n",
    "1. Create inputs for n-sized (when unrolled RNN), and then the same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs = 8\n",
    "c_in_dat = [[idx[i+n] for i in range(0, len(idx)-1-cs, cs)] for n in range(cs)]\n",
    "c_out_dat = [idx[i+cs] for i in range(0, len(idx)-1-cs, cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [np.stack(c[:-2]) for c in c_in_dat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, (75110,))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xs), xs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.stack(c_out_dat[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding_input(name, n_in, n_out):\n",
    "    inp = Input(shape=(1,), dtype='int64', name=name+'_in')\n",
    "    emb = Embedding(n_in, n_out, input_length=1, name=name+'_emb')(inp)\n",
    "    return inp, Flatten()(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_ins = [embedding_input('c'+str(n), vocab_size, n_fac) for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_in = Dense(n_hidden, activation='relu')\n",
    "dense_hidden = Dense(n_hidden, activation='relu', init='identity')\n",
    "dense_out = Dense(vocab_size, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden = dense_in(c_ins[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,cs):\n",
    "    c_dense = dense_in(c_ins[i][1])\n",
    "    hidden = dense_hidden(hidden)\n",
    "    hidden = merge([c_dense, hidden])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_out = dense_out(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([c[0] for c in c_ins], c_out)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "75110/75110 [==============================] - 11s - loss: 2.5336    \n",
      "Epoch 2/12\n",
      "75110/75110 [==============================] - 10s - loss: 2.2537    \n",
      "Epoch 3/12\n",
      "75110/75110 [==============================] - 10s - loss: 2.1489    \n",
      "Epoch 4/12\n",
      "75110/75110 [==============================] - 10s - loss: 2.0778    \n",
      "Epoch 5/12\n",
      "75110/75110 [==============================] - 10s - loss: 2.0202    \n",
      "Epoch 6/12\n",
      "75110/75110 [==============================] - 10s - loss: 1.9728    \n",
      "Epoch 7/12\n",
      "75110/75110 [==============================] - 10s - loss: 1.9344    \n",
      "Epoch 8/12\n",
      "75110/75110 [==============================] - 10s - loss: 1.8961    \n",
      "Epoch 9/12\n",
      "75110/75110 [==============================] - 10s - loss: 1.8642    \n",
      "Epoch 10/12\n",
      "75110/75110 [==============================] - 10s - loss: 1.8361    \n",
      "Epoch 11/12\n",
      "75110/75110 [==============================] - 10s - loss: 1.8068    \n",
      "Epoch 12/12\n",
      "75110/75110 [==============================] - 10s - loss: 1.7837    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1624e8beac8>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xs, y, batch_size=64, nb_epoch=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = [np.array(char_indices[c])[np.newaxis] for c in inp]\n",
    "    p = model.predict(idxs)\n",
    "    return chars[np.argmax(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('every on')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our first RNN with Keras\n",
    "The same as before but using Keras' SimpleRNN layer instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden, n_fac, cs, vocab_size = (256, 42, 8, 86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_fac, input_length=cs),\n",
    "    SimpleRNN(n_hidden, activation='relu', inner_init='identity'),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_5 (Embedding)          (None, 8, 42)         3612        embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "simplernn_1 (SimpleRNN)          (None, 256)           76544       embedding_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 86)            22102       simplernn_1[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 102,258\n",
      "Trainable params: 102,258\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "75110/75110 [==============================] - 8s - loss: 2.7821     \n",
      "Epoch 2/8\n",
      "75110/75110 [==============================] - 7s - loss: 2.2727     \n",
      "Epoch 3/8\n",
      "75110/75110 [==============================] - 7s - loss: 2.0666     \n",
      "Epoch 4/8\n",
      "75110/75110 [==============================] - 7s - loss: 1.9237     \n",
      "Epoch 5/8\n",
      "75110/75110 [==============================] - 7s - loss: 1.8149     \n",
      "Epoch 6/8\n",
      "75110/75110 [==============================] - 7s - loss: 1.7329     \n",
      "Epoch 7/8\n",
      "75110/75110 [==============================] - 7s - loss: 1.6714     \n",
      "Epoch 8/8\n",
      "75110/75110 [==============================] - 7s - loss: 1.6162     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x162666e8ef0>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.concatenate(xs,axis=1), y, batch_size=64, nb_epoch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_keras(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = np.array(idxs)[np.newaxis,:]\n",
    "    p = model.predict(arrs)[0]\n",
    "    return chars[np.argmax(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_keras('this is ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_keras('part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_keras('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict chars 2 to n using chars 1 to n-1\n",
    "Feeds each predicted character back in to improve the next character prediction. More learning going on for the same amount of computation!\n",
    "\n",
    "1 -> 2\n",
    "1 2 -> 3\n",
    "1 2 3 -> 4\n",
    "1 2 3 4 -> 5\n",
    "etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
